{"cells":[{"metadata":{"_execution_state":"idle","_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) # metapackage of all tidyverse packages\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist.files(path = \"../input\")\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's start with importing the required libraries and also suppressing any warnings\n* keras - We will be using keras for building our models and also loading our data\n* imager - This will be used mainly for plotting the images "},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"suppressMessages(library(keras))\nsuppressMessages(library(imager))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Global Constants"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"We will now define some constants that we are going to be using throughout the notebook such as training, validation and testing directories, image sizes and so on\n\n* train_dir, validation_dir, test_dir - Directory paths in order to load the images\n* image_size - As neural networks work with same size for all images, so we declare a fixed size for loading the images\n* epochs - Shows the total number of epochs that the model will be trained\n* output_classes - Shows the classes available here i.e, Normal and Pneumonia\n* batch_size - Images will be loaded in batches in order to make sure that the RAM is utilized efficiently\n* random_seed - In order to reproduce the results, we use the same random seed every time"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"train_dir <- '../input/chest-xray-pneumonia/chest_xray/chest_xray/train/'\nvalidation_dir <- '../input/chest-xray-pneumonia/chest_xray/chest_xray/val/'\ntest_dir <- '../input/chest-xray-pneumonia/chest_xray/chest_xray/test/'\n\nepochs <- 100\nimage_size <- c(224, 224)\nrandom_seed <- 123\noutput_classes <- c('NORMAL', 'PNEUMONIA')\nbatch_size <- 32","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Problem Understanding"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's start with first defining the problem in hand:\n\n> We want to build a Machine Learning model to classify x-ray images into 'NORMAL' and 'PNEUMONIA' classes\n\nAs we can see here that this is a classification problem and infact a binary classification problem. And we know that Convolutional Neural Networks (CNNs) are best at capturing various features in the images and can thus be good at classifying.\n\nSo now we know about the problem and the machine learning algorithm that we are going to use, we can look deeper into the data and then start working with different configurations of CNN to choose the best model"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Data Understanding (Exploratory Data Analysis)"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Lets dive deeper into the data. First lets see how many images are there in each class in respective training, validation and testing sets"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"train_normal_images <- list.files(paste0(train_dir, output_classes[1]))\ntrain_pneumonia_images <- list.files(paste0(train_dir, output_classes[2]))\n\nvalidation_normal_images <- list.files(paste0(validation_dir, output_classes[1]))\nvalidation_pneumonia_images <- list.files(paste0(validation_dir, output_classes[2]))\n\ntest_normal_images <- list.files(paste0(test_dir, output_classes[1]))\ntest_pneumonia_images <- list.files(paste0(test_dir, output_classes[2]))\n\ntotal_normal_images <- c(train_normal_images, validation_normal_images, test_normal_images)\ntotal_pneumonia_images <- c(train_pneumonia_images, validation_pneumonia_images, test_pneumonia_images)\n\ntotal_train_images <- c(train_normal_images, train_pneumonia_images)\ntotal_validation_images <- c(validation_normal_images, validation_pneumonia_images)\ntotal_test_images <- c(test_normal_images, test_pneumonia_images)\n\ntotal_images <- c(total_normal_images, total_pneumonia_images)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"print(paste0('Total number of images: ', length(total_images)))\nprint(paste0('Total number of Training images: ', length(total_train_images)))\nprint(paste0('Total number of Validation images: ', length(total_validation_images)))\nprint(paste0('Total number of Testing images: ', length(total_test_images)))\n\nprint(paste0('Total number of Normal images: ', length(total_normal_images)))\nprint(paste0('Total number of Normal Training images: ', length(train_normal_images)))\nprint(paste0('Total number of Normal Validation images: ', length(validation_normal_images)))\nprint(paste0('Total number of Normal Testing images: ', length(test_normal_images)))\n\nprint(paste0('Total number of Pneumonia images: ', length(total_pneumonia_images)))\nprint(paste0('Total number of Pneumonia Training images: ', length(train_pneumonia_images)))\nprint(paste0('Total number of Pneumonia Validation images: ', length(validation_pneumonia_images)))\nprint(paste0('Total number of Pneumonia Testing images: ', length(test_pneumonia_images)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Lets also construct bar charts to show these values"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"total <- c(length(total_images), length(total_train_images), length(total_test_images), length(total_validation_images))\ntotal_args <- c('Total', 'Training', 'Testing', 'Validation')\n\nnormal <- c(length(total_normal_images), length(train_normal_images), length(test_normal_images), length(validation_normal_images))\nnormal_args <- c('Total', 'Training', 'Testing', 'Validation')\n\npneumonia <- c(length(total_pneumonia_images), length(train_pneumonia_images), length(test_pneumonia_images), length(validation_pneumonia_images))\npneumonia_args <- c('Total', 'Training', 'Testing', 'Validation')\n\n\nbarplot(total, names.arg=total_args, xlab='Distribution', ylab='Number of Images', main='Distribution of Total images')\nbarplot(normal, names.arg=normal_args, xlab='Distribution', ylab='Number of Images', main='Distribution of Normal images')\nbarplot(pneumonia, names.arg=pneumonia_args, xlab='Distribution', ylab='Number of Images', main='Distribution of Pneumonia images')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Lets visualize some images belonging to each class. For this, we will write a helper function"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"normal_train_folder <- '../input/chest-xray-pneumonia/chest_xray/chest_xray/train/NORMAL/'\npneumonia_train_folder <- '../input/chest-xray-pneumonia/chest_xray/chest_xray/train/PNEUMONIA/'\n\nplot_images <- function(folder, images) {\n    par(mfrow=c(2,2))\n    \n    for(i in 1:4) {\n        image <- load.image(paste0(folder, images[i]))\n        plot(image)\n    }\n}","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Normal Images**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"plot_images(normal_train_folder, train_normal_images)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Pneumonia Images**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"plot_images(pneumonia_train_folder, train_pneumonia_images)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Now before we start modeling and training the models on the data, we need to prepare the data to be ready for training. For this, we will use `image_data_generator` from `keras` library to rescale the images on the fly. Rescaling helps in making the training process faster. We will start with just rescaling and then add augmentation to understand how it improves our evaluation"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"The way the `image_data_generator` works is if it has a folder that contains images in different folders with the classes names. For instance, there will be a 'NORMAL' and a 'PNEUMONIA' folder inside the train folder. It will load images batch wise and assign labels according to its parent folder. It will also apply rescaling as it loads the images"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"train_datagen = image_data_generator(rescale = 1/255,)\nvalidation_datagen <- image_data_generator(rescale = 1/255)  \ntest_datagen <- image_data_generator(rescale = 1/255)  \n\ntrain_generator <- flow_images_from_directory(\n  train_dir,                            \n  train_datagen,                        \n  classes = output_classes,\n  target_size = image_size,            \n  batch_size = batch_size,\n  class_mode = \"categorical\",\n  shuffle = TRUE,\n  seed = random_seed\n)\n\nvalidation_generator <- flow_images_from_directory(\n  validation_dir,\n  classes = output_classes,\n  validation_datagen,\n  target_size = image_size,\n  batch_size = batch_size,\n  class_mode = \"categorical\",\n  shuffle = TRUE,\n  seed = random_seed\n)\n\ntest_generator <- flow_images_from_directory(\n  test_dir,\n  classes = output_classes,\n  test_datagen,\n  target_size = image_size,\n  batch_size = 1,\n  class_mode = \"categorical\",\n  shuffle = FALSE\n)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Now comes the most interesting part, *the modelling and training part*. We will start with the most basic models and then go onto adding more complex models such as with transfer learning"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Model 1: CNN from Scratch "},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Building**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Our first model will be building a CNN from scratch with no augmentation or transfer learning"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Any CNN consists of a sequence of convolutional and pooling layers followed by around a couple of fully connected layers at the end. As we go forward, the height and width of the image decreases but the depth increases. For instance, at the start the input size will be (224, 224, 3) but after the first convolutional layer, the depth increases to 32 (filter size) and the max pooling layer reduces the width and height by a factor of 2"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Finally, the image is flattened (like a vector) and then fed into fully connected layers. It outputs 2 neurons at last which shows probability of the image being one of the output classes (Normal and Pneumonia)."},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"The activation functions used here are 'relu' and 'softmax'. The intermediate layers use 'relu' which is just the function max(x, 0) which means take the value if its positive otherwise 0. The 'softmax' function on the otherhand calculates the probability of each neuron and that's why its used at the last layer"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"model_scratch <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = \"relu\", \n                input_shape = c(224,224,3)) %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = \"relu\") %>%\n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_flatten() %>% \n  layer_dense(units = 64, activation = \"relu\") %>% \n  layer_dense(units = 2, activation = \"softmax\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's analyze the summary of the model"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"summary(model_scratch)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's compile the model with loss and optimizer. Finally we will train the model"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Training**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"First, we have to compile the model with appropriate loss, optimizer and metrics. The loss function used here is 'categorical_crossentropy' because there are multiple classes but each image belongs to a single class. For multi-label classification, you would use 'binary_crossentropy'. The optimizer used here is 'rmsprop' as it helps with faster learning. You can use Adam too. In the metrics, I have only included 'accuracy' but you can add more like loss, f1 score etc."},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"set.seed(123)\n\nmodel_scratch %>% compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_rmsprop(lr = 1e-6),\n  metrics = c(\"accuracy\")\n)\n\nvalidation_steps <- ceiling(length(total_validation_images) / batch_size)\n\nhistory <- model_scratch %>% fit_generator(\n  train_generator,\n  steps_per_epoch = 100,\n  epochs = epochs,\n  validation_data = validation_generator,\n  validation_steps = validation_steps,\n  verbose = 1\n)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's plot the metrics now"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"plot(history)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"We will now evaluate the model on the test set"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Evaluation**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"preds = evaluate_generator(model_scratch,\n                          test_generator,\n                          steps = length(total_test_images))\npreds","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"So we have achieved an accuracy of **75.6** using our CNN model from scratch. Let's use transfer learning now"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Model 2: Transfer Learning "},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Building**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"In the previous section, we had to train our model from scratch which not only takes much longer but is not deep enough to understand the features in the image. For this purpose, we will use Transfer Learning. Transfer Learning is basically taking a model that somebody has trained already for hundreds of epochs on millions of images and attach your own model to it for faster and more efficient training. "},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"We will start with an XceptionNet base and add our custom network to identify pneumonia in X-ray images. You can read more about XceptionNet [here](https://arxiv.org/abs/1610.02357)"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"conv_base <- application_xception(\n  weights = \"imagenet\",\n  include_top = FALSE,\n  input_shape = c(224, 224, 3)\n)\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"summary(conv_base)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's add our custom network and compile the model. We have to add our custom network as we have less output classes as compared to `imagenet` which contains 1000 classes."},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"model_xception <- keras_model_sequential() %>% \n  conv_base %>% \n  layer_global_average_pooling_2d(trainable = T) %>%\n  layer_dense(units = 1024, activation = \"relu\", trainable = T) %>% \n  layer_dropout(rate = 0.3, trainable = T) %>%\n  layer_dense(units = 512, activation = \"relu\", trainable = T) %>% \n  layer_dropout(rate = 0.2, trainable = T) %>%\n  layer_dense(units = 256, activation = \"relu\", trainable = T) %>% \n  layer_dropout(rate = 0.2, trainable = T) %>%\n  layer_dense(units = 2, activation = \"softmax\", trainable = T)\n\n#Don't train the base,\nfreeze_weights(conv_base)\n\nset.seed(123)\n\nmodel_xception %>% compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_rmsprop(lr = 1e-6),\n  metrics = c(\"accuracy\")\n)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Training**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"history <- model_xception %>% fit_generator(\n  train_generator,\n  steps_per_epoch = 100,\n  epochs = epochs,\n  validation_data = validation_generator,\n  validation_steps = validation_steps,\n  verbose = 1\n)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"plot(history)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Evaluation**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"preds = evaluate_generator(model_xception,\n                          test_generator,\n                          steps = length(total_test_images))\npreds","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"So we have achieved an accuracy of **78.6** using our Transfer Learning model (XceptionNet). "},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Model 3: Transfer Learning with Augmentation"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Building**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"Here, we would use the same model as above (Xception) but will change our `train_generator` so that it applies data augmentation i.e, rotation, zoom, shift etc. This allows the model to classify any image currently irrespective of its position in the overall image.\n\nThis is especially required because the real world images are from different angles such as zoomed in, rotated or the subject of the image is at different parts of the image. As a human, we can understand this but for machines, they deal with pixel values and thus for them, its completely different. That's why we will be using data augmentation to help tackle this issue. We are using the Transfer Learning model as it performed better than the model we trained from scratch\n\n\nWe don't do it for the validation or test set because we want to predict on those and hence we use them as such"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"train_datagen = image_data_generator(\n  rescale = 1/255,\n  rotation_range = 5,\n  width_shift_range = 0.1,\n  height_shift_range = 0.05,\n  shear_range = 0.1,\n  zoom_range = 0.15,\n  horizontal_flip = TRUE,\n  vertical_flip = FALSE,\n  fill_mode = \"reflect\"\n)\n\ntrain_generator <- flow_images_from_directory(\n  train_dir,                            \n  train_datagen,                        \n  classes = output_classes,\n  target_size = image_size,            \n  batch_size = batch_size,\n  class_mode = \"categorical\",\n  shuffle = TRUE,\n  seed = random_seed\n)\n\nconv_base <- application_xception(\n  weights = \"imagenet\",\n  include_top = FALSE,\n  input_shape = c(224, 224, 3)\n)\n\n\nmodel_augmentation <- keras_model_sequential() %>% \n  conv_base %>% \n  layer_global_average_pooling_2d(trainable = T) %>%\n  layer_dense(units = 1024, activation = \"relu\", trainable = T) %>% \n  layer_dropout(rate = 0.3, trainable = T) %>%\n  layer_dense(units = 512, activation = \"relu\", trainable = T) %>% \n  layer_dropout(rate = 0.2, trainable = T) %>%\n  layer_dense(units = 256, activation = \"relu\", trainable = T) %>% \n  layer_dropout(rate = 0.2, trainable = T) %>%\n  layer_dense(units = 2, activation = \"softmax\", trainable = T)\n\n#Don't train the base,\nfreeze_weights(conv_base)\n\nset.seed(123)\n\nmodel_augmentation %>% compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_rmsprop(lr = 1e-6),\n  metrics = c(\"accuracy\")\n)\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Training**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"history <- model_augmentation %>% fit_generator(\n  train_generator,\n  steps_per_epoch = 100,\n  epochs = epochs,\n  validation_data = validation_generator,\n  validation_steps = validation_steps,\n  verbose = 1\n)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"plot(history)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Evaluation**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"preds = evaluate_generator(model_augmentation,\n                          test_generator,\n                          steps = length(total_test_images))\npreds","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"So we have achieved an accuracy of **84.6** using our Transfer Learning model (XceptionNet) with Data Augmentation. "},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Model 4: Using `class_weight` to counter class imbalance"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"As we saw earlier, that the number of images in NORMAL class are much lower than the images in PNEUMONIA class. We can use `class_weight` attribute during training to ensure that the loss function takes this class imbalance into account when penalizing the wrong predictions."},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"The model building part will be the same as the last section"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Building**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"conv_base <- application_xception(\n  weights = \"imagenet\",\n  include_top = FALSE,\n  input_shape = c(224, 224, 3)\n)\n\n\nmodel_class_weight <- keras_model_sequential() %>% \n  conv_base %>% \n  layer_global_average_pooling_2d(trainable = T) %>%\n  layer_dense(units = 1024, activation = \"relu\", trainable = T) %>% \n  layer_dropout(rate = 0.3, trainable = T) %>%\n  layer_dense(units = 512, activation = \"relu\", trainable = T) %>% \n  layer_dropout(rate = 0.2, trainable = T) %>%\n  layer_dense(units = 256, activation = \"relu\", trainable = T) %>% \n  layer_dropout(rate = 0.2, trainable = T) %>%\n  layer_dense(units = 2, activation = \"softmax\", trainable = T)\n\n#Don't train the base,\nfreeze_weights(conv_base)\n\nset.seed(123)\n\nmodel_class_weight %>% compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_rmsprop(lr = 1e-6),\n  metrics = c(\"accuracy\")\n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Training**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"In training, we will use the `class_weight` argument. We will calculate it as follows:"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"class_weight <- list(\n    '0'<- length(total_images) / length(total_normal_images),\n    '1'<- 1.0\n)\nclass_weight","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"This means for every 1 example of PNEUMONIA, we will consider around 3.7 examples of NORMAL images"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"history <- model_class_weight %>% fit_generator(\n  train_generator,\n  steps_per_epoch = 100,\n  epochs = epochs,\n  validation_data = validation_generator,\n  validation_steps = validation_steps,\n  verbose = 1,\n  class_weight = class_weight\n)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"plot(history)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Model Evaluation**"},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"preds = evaluate_generator(model_class_weight,\n                          test_generator,\n                          steps = length(total_test_images))\npreds","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"cell_type":"markdown","source":"So we have achieved an accuracy of **85.2** using our Transfer Learning model (XceptionNet) with Data Augmentation and `class_weight` inclusion. "},{"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.6.3"},"papermill":{"duration":1.050843,"end_time":"2020-11-16T14:21:10.868496","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2020-11-16T14:21:09.817653","version":"2.1.0"}},"nbformat":4,"nbformat_minor":4}